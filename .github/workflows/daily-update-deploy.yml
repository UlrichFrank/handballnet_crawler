name: Daily Update & Deploy to GitHub Pages

on:
  push:
    branches:
      - main
  schedule:
    # 20:00 UTC (21:00 CET/22:00 CEST) - using cron with daylight saving time offset
    # GitHub Actions interprets cron in UTC, so we use 20:00 UTC as base
    # Note: DST is automatically handled by GitHub Actions
    - cron: '0 20 * * *'
  workflow_dispatch:

env:
  PYTHON_VERSION: '3.10'
  NODE_VERSION: '18'

permissions:
  contents: write
  pages: write
  id-token: write

jobs:
  update-and-deploy:
    runs-on: ubuntu-latest
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    
    steps:
      # 1. Checkout CODE from main branch
      - name: Checkout code (main branch)
        uses: actions/checkout@v4
        with:
          ref: main
          fetch-depth: 0

      # 2. Checkout DATA from data branch into subdirectory
      - name: Checkout data (data branch)
        uses: actions/checkout@v4
        with:
          ref: data
          path: _data_branch
          sparse-checkout: frontend/public/data
          fetch-depth: 0

      # 3. Merge data from data branch into working directory
      - name: Merge data from data branch
        shell: bash
        run: |
          echo "ðŸ“¥ Loading previous game data from data branch..."
          if [ -d "_data_branch/frontend/public/data" ]; then
            mkdir -p frontend/public/data
            cp -r _data_branch/frontend/public/data/* frontend/public/data/ 2>/dev/null || true
            echo "âœ… Previous game data loaded successfully"
          else
            echo "â„¹ï¸  First run: no previous data to load"
          fi
          
          # Also load error log for retry mechanism
          if [ -f "_data_branch/frontend/public/error_log.json" ]; then
            cp _data_branch/frontend/public/error_log.json frontend/public/error_log.json
            echo "âœ… Previous error log loaded for retry mechanism"
          fi
          
          rm -rf _data_branch

      # Setup Python
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      # Setup Node
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      # Setup pnpm
      - name: Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: 10

      # Setup pnpm caching
      - name: Get pnpm store directory
        shell: bash
        run: |
          echo "STORE_PATH=$(pnpm store path --silent)" >> $GITHUB_ENV

      - name: Setup pnpm cache
        uses: actions/cache@v3
        with:
          path: ${{ env.STORE_PATH }}
          key: ${{ runner.os }}-pnpm-store-${{ hashFiles('**/pnpm-lock.yaml') }}
          restore-keys: |
            ${{ runner.os }}-pnpm-store-

      # Install Python dependencies
      - name: Install Python dependencies
        run: pip install -r requirements.txt

      # Install Node dependencies
      - name: Install Node dependencies
        run: pnpm install --force

      # Run Scraper
      - name: Run Scraper
        run: |
          echo "ðŸ“Š Starting scraper..."
          python scraper.py --config config.gh.json
          echo "âœ… Scraper completed"

      # Generate Graphics
      - name: Generate Graphics
        run: |
          echo "ðŸŽ¨ Generating graphics..."
          python generate_graphics_from_json.py --config config.gh.json
          echo "âœ… Graphics generated"

      # Generate Excel Report
      - name: Generate Excel Report
        run: |
          echo "ðŸ“‹ Generating Excel report..."
          python generate_excel_report.py --config config.gh.json
          echo "âœ… Excel report generated"

      # Commit new game data to data branch
      - name: Commit and push game data to data branch
        shell: bash
        run: |
          echo "ðŸ“Š Checking data changes..."
          
          # Store paths for comparison
          NEW_DATA="${GITHUB_WORKSPACE}/frontend/public/data"
          
          # Check if data exists after scraper
          if [ ! -d "$NEW_DATA" ] || [ -z "$(find "$NEW_DATA" -type f 2>/dev/null)" ]; then
            echo "âš ï¸  No game data found after scraper - skipping push"
            rm -rf "${GITHUB_WORKSPACE}/_data_branch"
            exit 0
          fi
          
          echo "âœ… Game data found: $(find "$NEW_DATA" -type f | wc -l) files"
          
          # Check if error log exists
          HAS_ERROR_LOG=false
          if [ -f "${GITHUB_WORKSPACE}/frontend/public/error_log.json" ]; then
            echo "ðŸ“‹ Error log found"
            HAS_ERROR_LOG=true
          fi
          
          # Configure git
          cd "$GITHUB_WORKSPACE"
          git config user.name "GitHub Actions"
          git config user.email "actions@github.com"
          
          # Save data to temp before switching branches
          echo "ðŸ’¾ Saving data to temp location..."
          mkdir -p /tmp/scraped_data
          cp -r "$NEW_DATA"/* /tmp/scraped_data/ 2>/dev/null || true
          
          if [ $HAS_ERROR_LOG = true ]; then
            cp "${GITHUB_WORKSPACE}/frontend/public/error_log.json" /tmp/scraped_data/error_log.json
          fi
          
          # Push to data branch
          echo "ðŸ“ Pushing data to data branch..."
          git fetch origin data
          git checkout data
          
          # Copy saved data into data branch
          mkdir -p frontend/public/data
          cp -r /tmp/scraped_data/* frontend/public/data/ 2>/dev/null || true
          
          # Verify data was copied
          DATA_COUNT=$(find frontend/public/data -type f 2>/dev/null | wc -l)
          if [ "$DATA_COUNT" -eq 0 ]; then
            echo "âŒ Failed to copy data to data branch"
            cd "$GITHUB_WORKSPACE"
            git checkout main
            rm -rf "${GITHUB_WORKSPACE}/_data_branch" /tmp/scraped_data
            exit 1
          fi
          
          echo "âœ… Data copied: $DATA_COUNT files"
          
          # Add changes to git
          git add frontend/public/data/
          if [ $HAS_ERROR_LOG = true ]; then
            git add frontend/public/data/error_log.json
            echo "ðŸ“‹ Error log added to commit"
          fi
          
          # Check if there are changes to commit
          if ! git diff --cached --quiet; then
            git commit -m "chore: Update game data and error log from scraper [skip ci]"
            git push origin data
            echo "âœ… Data and error log pushed to data branch"
          else
            echo "â„¹ï¸  No new changes to commit"
          fi
          
          # Return to main branch
          git checkout main
          echo "âœ… Returned to main branch"
          
          # Ensure data exists for build (load from data branch if scraper had nothing)
          echo "ðŸ“¥ Ensuring game data is available for build..."
          if [ ! -d "frontend/public/data" ] || [ -z "$(find frontend/public/data -type f 2>/dev/null)" ]; then
            echo "âš ï¸  No data in working directory - loading from data branch..."
            mkdir -p /tmp/data_from_branch
            cd /tmp/data_from_branch
            git clone --branch data --depth 1 --single-branch https://github.com/${{ github.repository }}.git . 2>&1 | grep -E "Cloning|error" || true
            
            if [ -d "frontend/public/data" ]; then
              mkdir -p "${GITHUB_WORKSPACE}/frontend/public/data"
              cp -r frontend/public/data/* "${GITHUB_WORKSPACE}/frontend/public/data/" 2>/dev/null || true
              echo "âœ… Data loaded from data branch"
            else
              echo "âš ï¸  No data found in data branch either - build will proceed without data"
            fi
            
            cd "${GITHUB_WORKSPACE}"
            rm -rf /tmp/data_from_branch
          else
            echo "âœ… Data already available"
          fi
          
          # Cleanup
          rm -rf "${GITHUB_WORKSPACE}/_data_branch" /tmp/scraped_data

      # Build Frontend
      - name: Build Frontend
        run: |
          echo "ðŸ”¨ Building frontend..."
          pnpm run build
          echo "âœ… Frontend built successfully"
          
          # Copy static assets from public folder (SVGs, icons, etc.)
          echo "ðŸ“¦ Copying static assets..."
          # Copy all SVG files from public to dist
          if [ -d "frontend/public" ]; then
            find frontend/public -maxdepth 1 -name "*.svg" -exec cp {} frontend/dist/ \;
            echo "âœ… Copied SVG files"
          fi
          # Also ensure team-logo.svg specifically exists
          if [ -f "frontend/public/team-logo.svg" ]; then
            cp frontend/public/team-logo.svg frontend/dist/team-logo.svg
            echo "âœ… Ensured team-logo.svg is in dist"
          fi
          
          # Copy config to dist
          # Use config/config.gh.json for production since public/config.json is git-ignored
          if [ -f "config/config.gh.json" ]; then
            cp config/config.gh.json frontend/dist/config.json
            echo "âœ… Copied config/config.gh.json to dist/config.json"
          elif [ -f "frontend/public/config.json" ]; then
            cp frontend/public/config.json frontend/dist/config.json
            echo "âœ… Copied frontend/public/config.json to dist/config.json"
          else
            echo "âŒ No config file found to copy to dist!"
            # List available config files for debugging
            ls -la config/
            ls -la frontend/public/
          fi
          
          # Copy data directory
          if [ -d "frontend/public/data" ]; then
            cp -r frontend/public/data frontend/dist/data
            echo "âœ… Copied data directory to dist/"
          else
            echo "âŒ data directory not found in frontend/public!"
          fi
          
          # Copy error log for frontend status page
          if [ -f "frontend/public/error_log.json" ]; then
            cp frontend/public/error_log.json frontend/dist/error_log.json
            echo "âœ… Copied error log to dist/"
          fi
          
          # Verify
          echo "ðŸ“‚ Final dist structure:"
          ls -la frontend/dist/

      # Prepare deployment artifacts
      - name: Prepare deployment artifacts
        run: |
          mkdir -p deploy/handballnet_crawler
          
          # Copy everything from frontend/dist
          if [ -d "frontend/dist" ]; then
            cp -r frontend/dist/* deploy/handballnet_crawler/
            echo "âœ… Copied frontend dist"
          else
            echo "âŒ frontend/dist directory not found!"
          fi
          
          # Copy output (Excel, graphics)
          if [ -d "output" ]; then
            cp -r output deploy/handballnet_crawler/output || echo "âŒ Failed to copy output"
            echo "âœ… Copied output files"
          fi
          
          echo "ðŸ“¦ Deployment directory ready"
          ls -la deploy/handballnet_crawler/
          echo "---"
          ls -la deploy/handballnet_crawler/data/ 2>/dev/null || echo "No data folder"

      # Deploy to GitHub Pages using GitHub Actions
      - name: Upload artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: './deploy/handballnet_crawler'

      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4

      # Workflow summary
      - name: Workflow Summary
        if: always()
        run: |
          echo "## âœ… Deployment Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Date**: $(date -u +'%Y-%m-%d %H:%M:%S UTC')" >> $GITHUB_STEP_SUMMARY
          echo "- **Trigger**: ${{ github.event_name }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Status**: ${{ job.status }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Deployed to:" >> $GITHUB_STEP_SUMMARY
          echo "- [GitHub Pages](https://ulrichfrank.github.io/handballnet_crawler/)" >> $GITHUB_STEP_SUMMARY
# Trigger rebuild
